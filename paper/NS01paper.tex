\documentclass[doc, a4paper, apacite]{apa6}

\usepackage[american]{babel}

\usepackage{csquotes}
%\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber]{biblatex}
%\DeclareLanguageMapping{american}{american-apa}
\usepackage{nameref}
\usepackage{amsmath}

\title{Experimental exploration of attention in preferential choice}
\shorttitle{Attention in choice}

\author{C. E. R. Edmunds}
\affiliation{University of Warwick}

\abstract{}

\keywords{attention, preferential choice, decision making}

\begin{document}
\maketitle


\section{Experiment 1} \label{exp:NS01} 
\subsection{Method}
\subsubsection{Participants}
Data was collected from $67$ participants: $2$ of these were excluded because the eye-tracker would not initially calibrate and $12$ of these were excluded due to a coding error which meant the fixation cross did not work for them. This resulted in data being collected from $53$ participants. This is three more than pre-registered due to the vagaries of testing (i.e. trying to anticipate participants not showing up). All participants were recruited from the University of Warwickâ€™s volunteer subject pool and paid \pounds10 for their participation.

\subsubsection{Apparatus}
The participants were tested individually using an EyeLink 1000 Plus (SR Research, Osgoode, ON, Canada) eye-tracker. Monocular eye movements were recorded at 500Hz and fixations were identified by the eye tracker using velocity algorithms. The Areas of Interest were defined as a rectangle around the image position(s) on the screen. The experiment was displayed on a widescreen monitor (1920 x 1080 resolution, refresh). Participants were placed on a chin rest approximately 70cm away from the screen. Stimulus presentation was controlled by MATLAB using Psychtoolbox extensions \cite{Brainard1997, Pelli1997}.
% Need refresh rate

\subsubsection{Design}
All participants completed binary choice and strength-of-preference tasks in a counterbalanced order, followed by a final valuation task where they had to rate their overall liking for each picture on a Likert scale. 

\subsubsection{Stimuli and choices}
The stimuli were chosen from the International Affective Picture System \cite{Lang:2008}. The pictures were all positive in affect (average, male and female ratings between 5=neutral and 7=mildly positive) and had differences in value ratings of no more than 1.5 between male and female raters. After visual inspection, a further 7 images were removed for containing sexual images and 32 images were removed because they had a portrait aspect ratio. The 200 stimuli for each participant were randomly sampled without replacement from the 253 pictures that met these criteria. The participant's choices were generated by pairing the first stimulus with the hundred-and-first, the second with the hundred-and-second and so forth. 

\subsubsection{Procedure}
The experiment was displayed on a black background with white text and response scales. At the beginning of the experiment the participants were asked to provide their age and gender. Then, participants completed three tasks: the binary choice task, the strength-of-preference task and the valuation task. The order of the binary choice and strength-of-preference tasks were counterbalanced between participants. For each task, the participants were shown the instructions for the task, then the eye-tracker was calibrated and then they were shown a reminder of the task instructions at which point they had to give a left mouse click to start the task. At the beginning of each trial, a fixation cross was displayed in the center of the screen until the participant had looked at it. 

In both of the choice tasks, two landscape pictures (each $514 x 384px$) were displayed side by side after the fixation cross. The response scale was presented horizontally centered, below the stimuli. For the binary choice task, two labels (``Option A'' and ``Option B'') were shown underneath the appropriate stimuli. The current choice was signified by a red, square marker ($30 \times 30px$) above the label. For the strength of preference task, the response scale was a white bar displayed underneath the stimuli that extended from the middle of one stimulus to the middle of the other. A red marker slid along the bar to signify the amount of preference for each option. The end of the scales were marked ``Option A'' and ``Option B.'' In this task participants could move the marker to any point along the line using the mouse. In both tasks, the marker was initially centered equidistant between the two images. To respond in both tasks, the participants had to press the left mouse button. Reaction times were measured from the start of the trial to the beginning of the mouse click (i.e. the program did not wait for the release of the mouse button). A blank, black screen was displayed for $500ms$ between each trial.
% TODO Work out how far apart the stimuli were in pixels

In the final, valuation task, participants judged how much they liked each picture on a vertical Likert scale (1=strongly dislike, 7=strongly like). Each of the 200 stimuli were displayed once in a random order. Participants were offered the chance to take a self-paced break every 50 stimuli. A blank, black screen was displayed for $500ms$ between each rating. Throughout the experiment, the eye-tracker was validated every 25 trials.

\subsubsection{Data analysis}
\nameref{exp:NS01} was pre-registered at \url{https://aspredicted.org/19698}.
% Need to make public 
Also note that the continuous scale was split into a hundred bins. Areas of interest were defined as the area of the stimulus and a box around the response scales.

\subsection{Results}

\subsubsection{Additional exclusions}
One participant was excluded as they spent less than 60\% of the time on task during the binary experiment phase. 

As pre-registered, participants were excluded on a task by task basis. In previous eye-tracking research, we found that some participants spend a considerable amount of time off task, i.e. not looking at either the stimuli or the response scale. Here, only participant was found to be an outlier in the binary task and their data was removed. An outlier here is defined as the average proportion of time across all binary choice trials was less than the first quartile of all participants minus 1.5 times the interquartile range. This left 53 participants. 

We also pre-registered excluding trials for which the reaction time was less than $200ms$ or greater than the mean plus three standard deviations (this boundary was calculated across all trials). This resulted in $2.04\%$ of trials being removed from the strength-of-preference task, and $1.23\%$ of trials removed from the binary task. The maximum number of trials excluded for a single participant was $15$. There was no difference in the models if we included the information from all trials (see Appendix). 

Finally, there was one trial in the binary task where the participant was not registered as looking at either option. We removed this trial as it causes issues for calculating measures of attention. 

\subsubsection{Operationalizing value and attention}
Before proceeding to the analysis, here we briefly review the measures that are used in the mixed random effects models of choice below. Value was incorporated in the models as ``difference in value'' 
\begin{equation}
	\Delta_V = V_\text{left} - V_\text{right}
\end{equation}
where $V_i$ is the value of each stimulus taken from participants' judgements in the final valuation task. Attention was incorporated in the model as 
\begin{equation}
	A = \frac{T_\text{left}}{T_\text{left}+T_\text{right}}
\end{equation}
where $T_i$ is the total time spent fixating on option $i$. 

Finally, the interaction between value and attention was defined as
\begin{equation}
	\text{Interaction} = V_\text{left} A_\text{left} - V_\text{right} A_\text{right}.
\end{equation}
This interaction corresponds to the interaction term in the ADDM. For a proof, please see the Appendix. 

To predict reaction time, the constructs were defined similarly. For value and the interaction, we took the absolute value. For attention, we calculated
\begin{equation}
	|A| = \left| \frac{A_\text{left}}{A_\text{left}+A_\text{right}} - 0.5 \right| 
\end{equation}
so that the value of $|A|$ varied between zero and a half. These recoded variables were necessary as there was no reason to predict that participants would respond faster to a particular side or particular value. Rather, we would expect participants to respond faster the greater the absolute difference between the options in both attention or value. 
\subsubsection{Predicting reaction times}

\subsubsection{Predicting choice}


\section{Experiment 2} \label{exp:NS07}
\subsubsection{Participants}
Data was collected from $x$ participants: $y$ of these were excluded because the eye-tracker would not initially calibrate. This resulted in data being collected from $z$ participants. All participants were recruited from the University of Warwick's volunteer subject pool. Participants were paid a show up fee of \pounds 5. Additionally, one trial was randomly selected and then played out, so the participant could win an additional \pounds 1 to \pounds 8 depending on their choices. 

\subsubsection{Apparatus}
This experiment was delivered in the same manner as in \nameref{exp:NS01}. 

\subsubsection{Design}
This section describes the study's design.

\subsubsection{Stimuli and choices}

\subsubsection{Procedure}
The procedure was fairly straightforward, yet required
attention to detail.

\subsubsection{Data analysis}
\nameref{exp:NS07} was pre-registered at \url{}.
% Need to make and make public
Areas of interest were defined as a 100 pixel circle around each stimulus. 

\subsection{Results}

\subsubsection{Additional exclusions}

\subsubsection{Operationalizing attention and value}

\subsubsection{Predicting reaction times}

\subsubsection{Predicting choice}



\section{Discussion}
This is a lengthy and erudite discussion.  It demonstrates amazing
skill in interpreting the results for the masses.

\section{Open Practices Statement}
Both experiments were preregistered (see above). In addition, the data and analyses files are available by the Open Science Framework at \url{}. 

\clearpage
\newpage
\bibliographystyle{apacite}
\bibliography{references}

\clearpage
\newpage
\section{Appendices}

\subsection{Proof of interaction term}


\end{document}
