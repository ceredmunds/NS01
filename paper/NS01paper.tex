\documentclass[doc, a4paper, apacite]{apa6}

\usepackage[american]{babel}

\usepackage{csquotes}
%\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber]{biblatex}
%\DeclareLanguageMapping{american}{american-apa}
\usepackage{nameref}
\usepackage{amsmath}
\usepackage[document]{ragged2e} % to get ragged right

\usepackage{stackengine}
\def\yenrule{\rule{1.3ex}{.1ex}}
\def\textyen{\renewcommand\stacktype{L}\stackon[.4ex]{\stackon[.65ex]{Y}{\yenrule}}{\yenrule}}

\title{Experimental exploration of attention in preferential choice}
\shorttitle{Attention in choice}

\author{C. E. R. Edmunds}
\affiliation{University of Warwick}

\abstract{}

\keywords{attention, preferential choice, decision making}

\begin{document}
\maketitle


It seems obvious that attention is important in value-based choice; after all, it seems as if the entire premise of advertising is set up to grab attention and keep it focused on the positives, and away from the negatives. 
Similarly, in computer displays, air-traffic control and roadsides, much infrastructure is based on the idea that we can control attention and redirect it to change how people make decisions. 
Despite this ubiquity, we are still not certain how attention affects the mechanisms of value-based choices. 

Speaking to this uncertainty, there are several formal models of decision making that have attempted to include attention in the decision making mechanism. 
For instance, in the attentional drift diffusion model \cite<aDDM;>{Krajbich2010}, attention is hypothesised to exaggerate the difference in value between the two options. 
Briefly, the aDDM assumes a drift diffusion process where evidence is accumulated over time. 
Once the evidence hits a boundary, a choice is initiated. 
Attention in this model changes the rate at which evidence is accumulated. 
For instance, let us assume a choice between two options: `Left' and `Right.'
If the participant is gazing at the left option, the change in the drift rate is defined as $\Delta_V \propto V_\text{left} - \theta V_\text{right}$ where $\Delta_V$ is the change in drift rate, $V_i$ is the value of option $i$ and $\theta$ is a parameter between 0 and 1 that reflects the bias towards the fixated option. 
Similarly, if the participant is gazing at the right option, the change in drift is given as $\Delta_V \propto \theta V_\text{left} - V_\text{right}$. 

Thus, in this model, attention has a multiplicative effect on value. 
In other words, it moderates the drift rate depending on the value difference. 
The larger the value difference, the more attention will speed the drift rate. 
This is great, as it predicts many effects in the literature. 
For instance, this predicts that the higher the total value of the choice, the faster the choice should be made \cite{Smith2019}.

Similarly, in our lab we have also found some evidence that attention has a multiplicative effect.  
Mainly, in complex multi-attribute choice tasks. 
For instance, in one experiment participants had to choose between two apartments. 
These choices were laid out in an attribute list. 
In this experiment, there was an interaction effect at the level of the individual attributes values, not at the level of the overall item values. 
Similar effects were found in tasks asking about EQ5D health outcome choices, binary social dilemma choices, and (more weakly) in risky gamble choices. 

However, other models predict that attention should have an additive effect. 

We have found this to be the case in simple choices between pairs of foods, pictures, or pictures of politicians. 
The effect of attention shows no interaction with the value of the item being attended. 
Perhaps you might argue that these tasks are so different this is to be expected. 
After all, in the later tasks, the information is integrated in a single image whereas in the earlier tasks it was spaced out by attribute. 
However, in another experiment participants were asked to choose between two lotteries each consisting of three, equally likely tickets. 
This experiment had a layout much more similar to the multi-attribute choice tasks: the information of each option was spaced out across the screen. 
In this data, there was no interaction effect at the level of the attributes (when assuming screen position defines attributes). 

These results initially led us to question whether it is the specific simplicity of those binary choice tasks which results in no interaction effect. 
Although the lottery experiment also showed no interaction effect, it was the only multi-attribute task where the outcomes were completely identical and simply interpretable. 
The choices had the same numeric scale (unlike e.g. apartment choices), the same attribute scale as all were financial payouts (unlike e.g. health choices) and referred to equally likely single outcomes with no associated consequences or information which had to be integrated from other visual locations (e.g. the associated payout for self vs. other in social dilemma choice).

One possible explanation is that in simple binary choice, one often only need assess the two options with very rough accuracy to determine which is better. 
Thus, if one were forced to make a more specific judgement about the degree or strength of relative preference then this makes the task more complex. 
Similarly to the EQ5D experiments where valuation requires processing of all the information. 
This additional depth of processing may result in an interaction becoming evident. 
This would be a significant advance as it shows that attention has qualitatively different impacts in different tasks, or the interaction effect is only present when depth of processing requirements are high. 
This is why we ran Experiment 1. 

In Experiment 1, we attempted to manipulate depth of processing by changing the response options. 
In one condition, as in the previous experiments, participants had to simply choose their preferred option. 
In the other condition, participants had to try to judge not only which one they preferred but by how much. 
By extending the responses, we hoped to tap into the same processes that might happen in the more complex multi-attribute choices where you have to more closely estimate the difference in value in order to make your choice. 
This did not work. 


%Furthermore, in the EQ5D experiments, there were interesting patterns in attention itself. More attention was given to attributes that had a greater weighting in behavioural responses overall, and more severe (higher value) information was attended to for longer. However, this effect was weak overall, becoming stronger when one controlled for the fact that many choices were dominated, or particularly easy. On many trials, a decision was made before all information had been attended even once, meaning there was little possibility for ever identifying any interaction effect. In the valuation task, there was a noticeably stronger correlation between attention and attribute weighting, and rating severity. Here, the more complex task inherently required participants to consider and integrate all attributes to be able to form a specific rating. 

\section{Experiment 1} \label{exp:NS01} 
\subsection{Method}
\subsubsection{Participants}
Data collection was attempted from 67 participants. Of these, two were excluded as the eye-tracker would not initially calibrate and another 12 were excluded due to a coding error that resulted in the fixation cross not working for them. This resulted in usable data from 53 people.\footnote{Note that this is three more than preregistered due to errors in anticipating how many participants would show up.} All participants were recruited from the University of Warwick's volunteer subject pool and paid \pounds10 for their participation.

\subsubsection{Apparatus}
The participants were tested individually using an EyeLink 1000 Plus (SR Research, Osgoode, ON, Canada) eye-tracker and a chin rest approximately 70cm away from the screen to limit head movements. Monocular eye movements were recorded at 500Hz and fixations were identified by the eye tracker using velocity algorithms. The experiment was displayed on a widescreen monitor (1920 x 1080 resolution, refresh) and stimulus presentation was controlled by MATLAB using Psychtoolbox extensions \cite{Brainard1997, Pelli1997}.
% Need refresh rate

\subsubsection{Stimuli and choices}
The stimuli were chosen from the International Affective Picture System \cite{Lang:2008}. The pictures were all positive in affect (average, male and female ratings between 5=neutral and 7=mildly positive) and had differences in value ratings of no more than 1.5 between male and female raters. After visual inspection, a further 7 images were removed for containing sexual images and 32 images were removed because they had a portrait aspect ratio. The 200 stimuli for each participant were randomly sampled without replacement from the 253 pictures that met these criteria. The participant's choices were generated by pairing the first stimulus with the hundred-and-first, the second with the hundred-and-second and so forth. 

\subsubsection{Procedure}
The experiment was displayed on a black background with white text and response scales. At the beginning of the experiment the participants were asked to describe their age and gender. Then, the experiment consisted of three tasks: the binary choice task, the strength-of-preference task and the valuation task. All participants completed binary choice and strength-of-preference tasks in a counterbalanced order followed by a valuation task where they rated their overall liking for each picture on a Likert scale. For all tasks, the participants were shown the instructions for the task, then the eye-tracker was calibrated and then they were shown a reminder of the task instructions at which point they had to give a left mouse click to start the task. The eye-tracker was re-validated every 25 trials throughout the experiment. At the beginning of each trial, a fixation cross was displayed in the center of the screen until the participant had fixated on it. 

In the choice tasks, two landscape pictures (each $514 \times 384px$) were displayed side by side after the fixation cross. The response scale was presented horizontally centered, below the stimuli. For the binary choice task, two labels (``Option A'' and ``Option B'') were shown underneath the appropriate stimuli. The current choice was signified by a red, square marker ($30 \times 30px$) above the label. For the strength of preference task, the response scale was a white bar displayed underneath the stimuli that extended from the middle of one stimulus to the middle of the other. A red marker slid along the bar to signify the amount of preference for each option. The end of the scales were marked ``Option A'' and ``Option B.'' In this task participants could move the marker to any point along the line using the mouse. In both tasks, the marker was initially centered equidistant between the two images and participants needed to press the left mouse button to respond. Reaction times were measured from the start of the trial to the beginning of the mouse click (i.e. the program did not wait for the release of the mouse button). A blank, black screen was displayed for $500ms$ between each trial.
% TODO Work out how far apart the stimuli were in pixels

Finally, in the valuation task participants judged how much they liked each picture on a vertical Likert scale (1=strongly dislike, 7=strongly like) displayed to the left of the stimulus. Each of the 200 stimuli were displayed once in a random order. Participants were offered the chance to take a self-paced break every 50 stimuli. A blank, black screen was displayed for $500ms$ between each rating. 

\subsubsection{Data analysis}
\nameref{exp:NS01} was pre-registered at \url{https://aspredicted.org/19698}.
% Need to make public 
The continuous responses given in the strength of preference task were split into a hundred bins. Areas of interest were defined as the area of the stimulus. Additionally, we defined a box around the response scales so as to estimate the time participants spent on task. 

\subsection{Results}

\subsubsection{Additional exclusions}
As pre-registered, participants were excluded on a task by task basis. In previous eye-tracking research, we found that some participants spend a considerable amount of time off task, i.e. not looking at either the stimuli or the response scale. Here, only one participant was found to be an outlier in the binary task and all their data was removed. An outlier here is defined as the average proportion of time across all binary choice trials was less than the first quartile of all participants minus 1.5 times the interquartile range. This left 52 participants. 

As pre-registered, we also excluded trials for which the reaction time was less than $200ms$ or greater than the mean plus three standard deviations (this boundary was calculated across all trials). This resulted in $2.04\%$ of trials being removed from the strength-of-preference task, and $1.23\%$ of trials removed from the binary task. The maximum number of trials excluded for a single participant was $15$. There was no difference in the models if we included the information from all trials (see Appendices). 

Finally, there was one trial in the binary task where the participant was not registered as looking at either option. We removed this trial as it causes issues for calculating measures of attention. 

\subsubsection{Operationalizing value and attention}
Before proceeding to the analysis, here we briefly define the measures that are used in the mixed random effects models of choice below. Value was incorporated in the models as ``difference in value'' 
\begin{equation}
	\Delta_V = V_\text{left} - V_\text{right}
\end{equation}
where $V_i$ is the value of each stimulus taken from participants' judgements in the final valuation task. Attention was incorporated in the model as 
\begin{equation}
	A = \frac{T_\text{left}}{T_\text{left}+T_\text{right}}
\end{equation}
where $T_i$ is the total time spent fixating on option $i$. Finally, the interaction between value and attention was defined as
\begin{equation}
	\text{Interaction} = V_\text{left} A - V_\text{right} (1-A).
\end{equation}
This interaction corresponds to the combination of attention and value predicted by the attentional drift diffusion model \cite{Krajbich2010}. Please see Appendices for proof. 

To predict reaction time, the constructs were defined similarly. For value and the interaction, we took the absolute value. For attention, we calculated
\begin{equation}
	|A| = \left| \frac{A_\text{left}}{A_\text{left}+A_\text{right}} - 0.5 \right| 
\end{equation}
so that the value of $|A|$ varied between zero and a half. These recoded variables were necessary as there was no reason to predict that participants would respond faster to a particular side or particular value. Rather, we would expect participants to respond faster the greater the absolute difference between the options in both attention or value. 

\subsubsection{Predicting choice}
To consider a mixed effects model of choice, we recoded the responses given in the strength-of-preference task as binary.

To look for order effects, we looked at the general linear model that predicts choice on the basis of task, attention, value difference, task order and their interactions. We found significant effects of task order ($p<.001$) and a significant interaction of task order with attention ($p=.004$). Therefore, as pre-registered, in the following we only analyse the first block. 

\input{tables/NS01choiceModel.tex}

\section{Discussion}


\section{Experiment 2} \label{exp:NS07}
Another possibility is that a primary role of attention is to weight different pieces of information when they cannot be thought about or conceived of simultaneously. 
This would explain why we find the interaction effect in the complex multi-attribute choice tasks, where the different attributes cannot be thought about on the same subjective scale (e.g. pain vs depression in EQ5D, or crime safety vs commute time in apartment choice). 
It would also explain why there is no interaction in the Nikhil data (everything on the same scale), or the simple binary choices. 
Therefore, in Experiment 2 we examined whether there is an interaction effect at the attribute level for a task where the attributes are non-commensurate (i.e. they cannot be easily thought of on the same scale), but not when they are commensurate. 
% ^ Terrible sentence, fix. 
This would be a significant advance as it would be a major component of explaining how different information is weighted and integrated during complex choice. 
It would also feed into many existing behavioural models that contain an “attention” component, that has never been tested against any actual attention data. 
The results from Experiment 2 experiment show that there is no interaction effect in either condition at the level of the item value. 
We should further develop the analysis to examine whether the interaction effect is present at the attribute level.
	
\subsubsection{Participants}
Data was collected from $x$ participants: $y$ of these were excluded because the eye-tracker would not initially calibrate. This resulted in data being collected from $z$ participants. All participants were recruited from the University of Warwick's volunteer subject pool. Participants were paid a show up fee of \pounds 5. Additionally, one trial was randomly selected and then played out, so the participant could win an additional \pounds 1 to \pounds 8 depending on their choices. 

\subsubsection{Apparatus}
This experiment was delivered in the same manner as in \nameref{exp:NS01}. 

\subsubsection{Design}
All participants completed Commensurate and Noncommensurate trials where they made choices between two lotteries in a counterbalanced order. Each lottery had three equally likely outcomes.

\subsubsection{Stimuli and choices}
All participants completed a total of 84 trials where they chose between the top and bottom lottery, each of which had three equally likely outcomes. The outcomes were displayed in three kinds of experimental currencies. The subjects were notified of the conversion rates for these experimental currencies into British pounds (\textyen 21 = \pounds1, \$83 = \pounds 1, and $Q88$ = \pounds1) at the beginning of the experiment, and also periodically as they made choices among lotteries.
 
In the Commensurate Condition, all outcomes for both the lotteries (three in each) were in the same currency. Lotteries in this condition either had all outcomes in \textyen, \$, or $Q$ currency. We balanced and randomized the trials so that all three currencies were present equally through the trials in this condition. In the Non-Commensurate Condition, for both lotteries, one outcome was in \textyen, one outcome was in \pounds\space and one outcome was in $Q$ currency. In every trial, the participants were asked to select the lottery that they preferred. 

Participants faced all trials of the Commensurate condition in one block, and did the same for all the trials of the Non-Commensurate condition. The order of the blocks was also randomized for each participant.

\subsubsection{Procedure}
The experiment was displayed on a black background with the six lottery outcomes presented in white text on a grey circle. At the beginning of the experiment the participants were asked to provide their age and gender. Then, participants completed 84 trials across two tasks: the Commensurate trials, and the NonCommensurate trials. Gamble outcomes, the order of the trials, and the blocks in which conditions were presented were all randomly determined for each participant. For each participant, the instructions for the tasks were shown, then the eye-tracker was calibrated and validated. At the beginning of each trial, a fixation cross was displayed in the center of the screen until the participant had looked at it. 

In all trials, participants had to press the up key if they preferred the top lottery, and the down key if they preferred the bottom lottery. Reaction times were measured from the start of the trial to the pressing of the up or down key. The areas of interest were placed at a horizontal distance of 320 pixels, and a vertical distance of 340 pixels apart on the screen. A blank, black screen was displayed for 500ms between each trial. Throughout the experiment, the eye-tracker was refreshed every 21 trials. At the end of the experiment, participants were issued with a risk aversion questionnaire.

\subsubsection{Data analysis}
\nameref{exp:NS07} was pre-registered at \url{}.
% Need to make and make public
Areas of interest were defined as the area of the stimulus, allowing for fixations up to 100 pixels from the centre of each stimuli circle. 

\subsection{Results}

\subsubsection{Additional exclusions}

\subsubsection{Operationalizing attention and value}

\subsubsection{Predicting reaction times}

\subsubsection{Predicting choice}

\section{General Discussion}
This is a lengthy and erudite discussion.  It demonstrates amazing
skill in interpreting the results for the masses.

\section{Open Practices Statement}
Both experiments were preregistered (see above). In addition, the data and analyses files are available by the Open Science Framework at \url{}. 

\clearpage
\newpage
\bibliographystyle{apacite}
\bibliography{references}

\clearpage
\newpage
\section{Appendices}
\subsection{Proof of interaction term}
In the Attentional Drift Diffusion Model (ADDM), the change in the value of the accumulator at time $t$ is given by 
\begin{equation}
	\Delta_V = d(V_L - \theta V_R) + \epsilon_t
\end{equation}
when the participant is staring at the left option and
\begin{equation}
	\Delta_V = d(\theta V_L - V_R) + \epsilon_t
\end{equation}
when staring at the right option. Here, $V_t$ is the value of the accumulator at time $t$, $d$ is a constant that affects the rate of integration, $V_L$ and $V_R$ are the values of the two options, $\theta$ is a number between 0 and 1 that reflects the bias towards the fixated option, and $\epsilon_t$ is Gaussian noise with variance $\sigma^2$. 

 This means that the final value of the accumulator, across all time $t$ in the trial, can be estimated by 
 \begin{equation}
 	V_{t=T} = \sum_{t \in L} \left(V_L - \theta V_R\right) + \sum_{t \in R}	\left(\theta V_L - V_R\right) 
 \end{equation}
 where each term is summed over the amount of time spent fixating on either the left or right options. Then, this can be summarised as 
 \begin{eqnarray}	
 	V_{t=T}&=& A_L\left(V_L -\theta V_R\right) + A_R \left(\theta V_L - V_R \right)\\
 	&=& A_L V_L - \theta A_L V_R + \theta A_R V_L - A_R V_R
 \end{eqnarray}
 where $A_i$ is the proportion of the time on task that participants looked at option $i$. Then, as $A_L + A_R = 1$, 
 \begin{eqnarray}
 	V_{t=T} &=& A_L V_L -\theta(1-A_R)V_R + \theta(1-A_L) V_L - A_R V_R \\
 		  &=& A_L V_L -\theta V_R + \theta A_R V_R + \theta V_L - \theta A_L V_L - A_R V_R \\
 		  &=& \theta(V_L - V_R) + (1-\theta)(A_L V_L - A_R V_R). \label{eqn:interaction}
 \end{eqnarray}
 The first term of equation \ref{eqn:interaction} gives the main effect of value and the second term gives the interaction between value and attention. 
 
\subsubsection{Note}
Here, we are assuming that the time spent not looking at areas of interest is absorbed into the non-decision time of the ADDM. Otherwise, we would have $A_L + A_R + A_\text{none} = 1 $. This makes things a little more interesting, depending on what you assume the drift rate is whilst people are not fixating on options. The interaction term remains the same. However, if you assume that people are not accumulating when they are not staring at options the first term becomes $\theta(1-A_\text{none})(V_L-V_R)=\theta(A_L + A_R)(V_L - V_R)$. If instead you assume that participants accumulate at the rate $(V_L-V_R)$ you get $T_\text{none}(V_L-V_R)$. Finally, if you assume that participants accumulate at $\theta(V_L-V_R)$, then you get $\theta (V_L - V_R)$. 
% CE: see p. 36-37 of notebook. 

\subsection{Analyses without excluding trials on the basis of reaction time}

\end{document}
