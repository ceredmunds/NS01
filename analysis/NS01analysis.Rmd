---
title: 'NS01: Binary choice vs. strength-of-preference'
author: "C E R Edmunds"
date: "20-02-2019"
output:
  html_document:
    df_print: paged
---

```{r Setup, message=F, echo=F, results='hide'}
rm(list=ls()) 

require(data.table); require(plyr); require(lme4); require(ggplot2); require(MuMIn)

fixations <- fread('NS01fixationsLong.csv', stringsAsFactors=F)

```

## Summary statistics
In total, we have `r length(unique(fixations$participantNo))` participants after excluding those for whom the fixation cross did not work (due to experimenter error) and 2 people for which the eye-tracker would not initially calibrate. 

## Exclusions
```{r Exclude participants for which I tracked wrong eye}
effedUp <- c(1)
badCalib <- c(6, 9, 11, 14, 15, 24, 26, 34, 10, 22, 42, 47) # Wrong eye

fixations <- fixations[!participantNo %in% badCalib,]
```

```{r Exclusions based on time on task: binary task, cache=T}
binary <- fixations[task=='binary' & intra_choice==1,]
binary[, onTask:= ifelse(aoi=="left" | aoi=="right" | aoi=="likertHorizontal", 1, 0)]
binary[, onTaskProp:= onTask*fixLengthTr/rt]
binary.summary <- as.data.table(aggregate(onTaskProp ~ participantNo + trial, data=binary, FUN=sum))

binary.summary.plot <- as.data.table(aggregate(onTaskProp ~ participantNo, data=binary.summary, FUN=mean))

boxplot(binary.summary.plot$onTaskProp)
# One outlier at around 0.53, propose cut off of 60% 

binary.histogram <- ggplot(binary.summary.plot, aes(x=onTaskProp)) + 
  geom_histogram(binwidth=0.01) +
  theme_minimal() +
  geom_vline(xintercept=0.6, colour="blue") +
  labs(title="Histogram of proportion of time on task for every participant in binary task", 
       x="Proportion of trial on task", y="Count") +
  xlim(c(0.5, 1))
binary.histogram

# Get excluded participant
binaryExclusions <- c(binary.summary.plot[onTaskProp<0.60, participantNo])

# Remove participant
fixations <- fixations[!participantNo %in% binaryExclusions,]

# Tidying
rm(binary.summary, binary.summary.plot)
```

```{r Exclusions based on time on task: continuous task, cache=T}
continuous <- fixations[task=='continuous' & intra_choice==1,]
continuous[, onTask:= ifelse(aoi=="left" | aoi=="right" | aoi=="likertHorizontal", 1, 0)]
continuous[, onTaskProp:= onTask*fixLengthTr/rt]
continuous.summary <- as.data.table(aggregate(onTaskProp ~ participantNo + trial, 
                                              data=continuous, FUN=sum))

continuous.summary.plot <- as.data.table(aggregate(onTaskProp ~ participantNo, 
                                                   data=continuous.summary, FUN=mean))

boxplot(continuous.summary.plot$onTaskProp)
# No outliers according to boxplot 

continuous.histogram <- ggplot(continuous.summary.plot, aes(x=onTaskProp)) + 
  geom_histogram(binwidth=0.01) + 
  theme_minimal() +
  labs(title="Histogram of time on task for every participant in continuous task", 
       x="Time on task", y="Count") +
  xlim(c(0.5, 1))
continuous.histogram

# Not really needed, due to lack of exclusions. There in case change mind.
# Get excluded participant(s)
continuousExclusions <- c(continuous.summary.plot[onTaskProp<0, participantNo])

# Remove participant
fixations <- fixations[!participantNo %in% continuousExclusions,]

# Tidying
rm(continuous.summary, continuous.summary.plot)
```
As preregistered, we excluded participants on the basis of time on task. Time on task was operationalized as the proportion of time during the trial where participants were fixating on either the pictures or the response scale. We then plotted a histogram of the mean proportion for each participant to determine where a natural break point would be. For the binary task, this turned out to be 0.60. This resulted in excluding `r length(binaryExclusions) + length(continuousExclusions)` participants, resulting in `r length(unique(fixations$participantNo))` remaining participants, who completed all trials.  

Additionally, we excluded all trials with reaction times less than 200ms and trials where the reaction time is 3 standard deviations above the mean reaction time across all task trials (i.e. not including the liking rating task).
```{r Exclusions based on reaction times}
# Excluding trials based on reaction times
fixations[, excludeTrial:= ifelse((rt<200 | rt>mean(rt)+3*sd(rt)) & task!="valuation", 1, 0)]

# Get break down of exclusions per task and per participant
rt.exclusions <- fixations[task!="valuation", list(excludeN=sum(excludeTrial)/.N), 
                      by=list(participantNo, trial, task)]
rt.exclusions.by.task <- rt.exclusions[, list(propExclude=sum(excludeN)/.N), by=task]
rt.exclusions.by.ppt <- rt.exclusions[, list(propExclude=sum(excludeN)/.N), by=.(participantNo)]

# Remove those trials
fixations <- fixations[excludeTrial==0,]
```
This resulted in excluding `r signif(rt.exclusions.by.task[task=="continuous", propExclude], 3)*100`% of trials in the continuous task, `r signif(rt.exclusions.by.task[task=="binary", propExclude], 3)*100`% of trials in binary task. The maximum number of trials excluded for a single participant was `r max(rt.exclusions.by.ppt$propExclude)*100`% across the two tasks. 

## Data exploration
```{r  Data exploration}

```


## Analysis
```{r Get data table for analysis, cache=T}
data <- dcast(fixations, participantNo + task + taskOrder + block + trial + response + rt +
                     lValue + rValue ~ aoi,
                   fun = sum, value.var="fixLengthProp")
data[, V1:=NULL]

data[, value.difference:=rValue-lValue]
data[, attention.difference:=right-left]

data[, response:=as.double(response)]
data[task=="binary", response:= response-1]
data[task=="continuous", response:= (response-1.0)/99.0]

data[, recodedResponse:= response]
data[task=="continuous", recodedResponse:= ifelse(recodedResponse<=0.5, 0, 1)]

data[, `:=`(participantNo=factor(participantNo), task=factor(task))]
```

```{r Analysis of binary task}
binary.full <- glmer(response ~ attention.difference*value.difference +
                       (1 + attention.difference*value.difference|| participantNo),
                     family="binomial", data=data[task=="binary",])
summary(binary.full)
```

```{r Analysis of continuous task}
continuous.full <- glmer(recodedResponse ~ attention.difference*value.difference +
                       (1 + attention.difference*value.difference|| participantNo),
                     family="binomial", data=data[task=="continuous",])
summary(continuous.full)

```

```{r Analysis of continuous task (continuous responses)}
# continuous.full <- lmer(response ~ attention.difference*value.difference +
#                         (1 + attention.difference*value.difference|| participantNo),
#                         data=data[task=="continuous",], glmerControl(optCtrl=list(maxfun=1e6)))
# summary(continuous.full)
```

```{r Including task as main effect}
# full <- glmer(recodedResponse ~ attention.difference*value.difference*task + 
#                                 (1 + attention.difference*value.difference*task||participantNo),
#                            data=data[task!="valuation",], 
#                            family="binomial", control=glmerControl(optCtrl=list(maxfun=1e6)))
# summary(full)
```



# Notes
So, in this analysis there is a `r signif(cor(data[task!="valuation", value.difference], data[task!="valuation", attention.difference]),3)` correlation between attention difference and value difference: participants seem to look at the higher value option for longer. However, the interaction is not 

# To do
- models by task (data[task=="cont"] etc.)
- full interaction model to show between task effect
- inverse-U relationship between value and rt? in rating tasks.


# To double check: you need to plot attention against value for the different quintiles, then plot the models for each person over top. 
To get the glm model fits for each person, it's something like:

fixations[task=="binary", .(model=glm(response ~ attention.difference*value.difference, data=.SD)), by=.(participantNo)]

or

lmList
