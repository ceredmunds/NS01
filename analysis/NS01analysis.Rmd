---
title: 'NS01: Binary choice vs. strength-of-preference'
author: "C E R Edmunds"
date: "20-02-2019"
output:
  html_document:
    df_print: paged
---

```{r Setup, message=F, echo=F, results='hide'}
rm(list=ls()) 

require(data.table); require(plyr); require(lme4); require(ggplot2); require(MuMIn)

data <- fread('NS01fixationsLong.csv', stringsAsFactors=F)

effedUp <- c(1)
badCalib <- c(6, 9, 11, 14, 15, 24, 26, 34, 10, 22, 42, 47) # Wrong eye

data <- data[!participantNo %in% badCalib,]
```

## Summary statistics
```{r Summary statistics, echo=FALSE}
N <- length(unique(data$participantNo))
```

### Participants
In total, we have `r N` participants after excluding those for whom the fixation cross did not work (due to experimenter error) and 2 people for which the eye-tracker would not initially calibrate. 

## Exclusions
```{r Exclusions based on time on task: binary task}
binary <- data[task=='binary' & intra_choice==1,]
binary[, onTask:= ifelse(aoi=="left" | aoi=="right" | aoi=="likertHorizontal", 1, 0)]
binary[, onTaskProp:= onTask*fixLengthTr/rt]
binary.summary <- as.data.table(aggregate(onTaskProp ~ participantNo + trial, data=binary, FUN=sum))

binary.summary.plot <- as.data.table(aggregate(onTaskProp ~ participantNo, data=binary.summary, FUN=mean))

boxplot(binary.summary.plot$onTaskProp)
# One outlier at around 0.53, propose cut off of 60% 

binary.histogram <- ggplot(binary.summary.plot, aes(x=onTaskProp)) + 
  geom_histogram(binwidth=0.01) +
  theme_minimal() +
  
  labs(title="Histogram of proportion of time on task for every participant in binary task", 
       x="Proportion of trial on task", y="Count") +
  xlim(c(0.5, 1))
binary.histogram

# Get excluded participant
binaryExclusions <- c(binary.summary.plot[onTaskProp<0.60, participantNo])

# Remove participant
data <- data[!participantNo %in% binaryExclusions,]

# Tidying
rm(binary.summary, binary.summary.plot)
```

```{r Exclusions based on time on task: continuous task}
continuous <- data[task=='continuous' & intra_choice==1,]
continuous[, onTask:= ifelse(aoi=="left" | aoi=="right" | aoi=="likertHorizontal", 1, 0)]
continuous[, onTaskProp:= onTask*fixLengthTr/rt]
continuous.summary <- as.data.table(aggregate(onTaskProp ~ participantNo + trial, 
                                              data=continuous, FUN=sum))

continuous.summary.plot <- as.data.table(aggregate(onTaskProp ~ participantNo, 
                                                   data=continuous.summary, FUN=mean))

boxplot(continuous.summary.plot$onTaskProp)
# No outliers according to boxplot 

continuous.histogram <- ggplot(continuous.summary.plot, aes(x=onTaskProp)) + 
  geom_histogram(binwidth=0.01) + 
  theme_minimal() +
  labs(title="Histogram of time on task for every participant in continuous task", 
       x="Time on task", y="Count") +
  xlim(c(0.5, 1))
continuous.histogram

# Not really needed, due to lack of exclusions. There in case change mind.
# Get excluded participant(s)
continuousExclusions <- c(continuous.summary.plot[onTaskProp<0, participantNo])

# Remove participant
data <- data[!participantNo %in% continuousExclusions,]

# Tidying
rm(continuous.summary, continuous.summary.plot)
```
As preregistered, we excluded participants on the basis of time on task. Time on task was operationalized as the proportion of time during the trial where participants were fixating on either the pictures or the response scale. We then plotted a histogram of the mean proportion for each participant to determine where a natural break point would be. For the binary task, this turned out to be 0.60. This resulted in excluding `r length(binaryExclusions) + length(continuousExclusions)` participants, resulting in `r length(unique(data$participantNo))` remaining participants. 

Additionally, we excluded all trials with reaction times less than 200ms and trials where the reaction time is 3 standard deviations above the mean reaction time across all trials.
```{r Exclusions based on reaction times}
# Excluding trials based on reaction times
data[, excludeTrial:= ifelse(rt<200 | rt>mean(rt)+3*sd(rt), 1, 0)]
data[, exclude:= excludeTrial/.N, by=list(participantNo, trial)]

# Summary of exclusions by reaction time
exclusions <- aggregate(data$exclude, list(data$participantNo), sum)
colnames(exclusions) <- c("participantNo", "nExclusions")
exclusions["percentExcluded"] <- (exclusions$nExclusions/300)*100
percentTrialsExcluded <- mean(exclusions$percentExcluded)

# Remove those trials
data <- data[excludeTrial==0,]
```

## Data exploration
```{r  Data exploration}

```


## Analysis
```{r Get data table for analysis}
fixations <- dcast(data, participantNo + task + taskOrder + block + trial + response + rt +
                     lValue + rValue ~ aoi,
                   fun = sum, value.var="fixLengthProp")
fixations[, V1:=NULL]

fixations[, value.difference:=rValue-lValue]
fixations[, attention.difference:=right-left]

fixations[, response:=as.double(response)]
fixations[task=="binary", response:= response-1]
fixations[task=="continuous", response:= (response-1.0)/99.0]

fixations[, recodedResponse:= response]
fixations[task=="continuous", recodedResponse:= ifelse(recodedResponse<=0.5, 0, 1)]
```

```{r Analysis of binary task}
fixations[, participantNoF:=as.factor(participantNo)]


# Neil's mess....
binary.full <- glmer(response ~ attention.difference*value.difference + 
                             (1 + attention.difference*value.difference || participantNo), family=binomial, 
                           data=fixations[task=="binary",])


# fixations[task=="binary", .(model=glm(response ~ attention.difference*value.difference, data=.SD)), by=.(participantNo)]

# lmList


summary(binary.full)

binary2 <-  glmer(response ~ attention.difference*value.difference + 
                             (1 | participantNo:attention.difference) +
                             (1 | participantNo:value.difference),
                           data=fixations[task=="binary",],
                           family=binomial)
summary(binary2)

binary1 <-  glmer(response ~ attention.difference*value.difference + 
                             (1 | participantNo:value.difference),
                           data=fixations[task=="binary",],
                           family=binomial)
summary(binary1)

binary0 <- lm(response~attention.difference*value.difference, data=fixations[task=="binary",])
summary(binary0)

anova(binary.full, binary2, binary0, binary1)

```

Think this means that binary1 is the best model: so main effects of attention and value, and nested random effects of value difference in participantNo. 

```{r Analysis of continuous task}
continuous.full <- glmer(recodedResponse ~ attention.difference*value.difference + 
                                (1|participantNo) + 
                                (1|participantNo:value.difference) +
                                (1|participantNo:attention.difference),
                           data=fixations[task=="continuous",], 
                           family="binomial", control=glmerControl(tol=0.01))
summary(continuous.full)

continuous2 <-  glmer(recodedResponse ~ attention.difference*value.difference + 
                             (1 | participantNo:attention.difference) +
                             (1 | participantNo:value.difference),
                           data=fixations[task=="continuous",],
                           family=binomial)
summary(continuous2)

continuous1 <-  glmer(recodedResponse ~ attention.difference*value.difference + 
                             (1 | participantNo:value.difference),
                           data=fixations[task=="continuous",],
                           family=binomial)
summary(continuous1)

continuous0 <- lm(recodedResponse~attention.difference*value.difference, 
              data=fixations[task=="continuous",])
summary(continuous0)

anova(continuous.full, continuous2, continuous0, continuous1)
```
Again, I think that means that continuous1 is the best model. Maybe :) 
```{r Analysis of continuous task (continuous responses)}
continuous.full <- lmer(response ~ attention.difference*value.difference + 
                                (1|participantNo) +
                                (1|participantNo:value.difference),
                           data=fixations[task=="continuous",])
summary(continuous.full)

continuous2 <-  lmer(response ~ attention.difference*value.difference + 
                             (1 | participantNo:value.difference),
                           data=fixations[task=="continuous",])
summary(continuous2)

continuous1 <-  glmer(recodedResponse ~ attention.difference*value.difference + 
                             (1 | participantNo),
                           data=fixations[task=="continuous",],
                           family=binomial)
summary(continuous1)

continuous0 <- lm(response~attention.difference*value.difference, 
              data=fixations[task=="continuous",])
summary(continuous0)

anova(continuous.full, continuous2, continuous0, continuous1)
# Continuous2 lowest AIC
```

```{r Including task as main effect}
full <- glmer(recodedResponse ~ attention.difference*value.difference*task + 
                                (1|participantNo) + 
                                (1|participantNo:value.difference) +
                                (1|participantNo:attention.difference),
                           data=fixations[task!="valuation",], 
                           family="binomial", control=glmerControl(tol=0.01))
summary(full)

task4 <- update(full, ~ . - attention.difference:value.difference:task)
summary(task4)

task3 <- update(task4, ~ . - value.difference:task)
summary(task3)

task2 <- update(task3, ~ . - attention.difference:value.difference)
summary(task2)

task1 <- update(task2, ~ . - task)
summary(task1)

task0 <- lm(recodedResponse ~ attention.difference*value.difference*task, 
            data=fixations[task!="valuation"])
summary(task0)

anova(full, task4, task3, task2, task1)
# AIC's get smaller as we decrease but don't really change that much. 
```
Seems like main effects of attention and value. Also, an interaction of task and attention: participants choices are guided more by attention in the continuous task than the binary task. I guess this matches our intuition that participants' choices are more considered in the continuous task than the binary one. 




# Notes
So, in this analysis there is a `r signif(cor(fixations[task!="valuation", value.difference], fixations[task!="valuation", attention.difference]),3)` correlation between attention difference and value difference: participants seem to look at the higher value option for longer. However, the interaction is not 




```{r Analysis of continuous responses}
attention.model <- glmer(response ~ attention.difference + 
                           (1 + attention.difference|participantNo), 
               data = fixations[task=="continuous"],
               family = binomial)
summary(attention.model)

value.model <- glmer(response ~ value.difference + 
                           (1 + value.difference|participantNo), 
               data = fixations[task=="continuous"],
               family = binomial)
summary(value.model)


attention.value.interaction <- glmer(response ~ attention.difference*value.difference + 
                           (1 + value.difference||participantNo), 
               data = fixations[task=="continuous"],
               family = binomial)
summary(attention.value.interaction)
```

# To do
- models by task (data[task=="cont"] etc.)
- full interaction model to show between task effect
- inverse-U relationship between value and rt? in rating tasks.
