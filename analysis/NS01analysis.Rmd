---
title: 'NS01: Binary choice vs. strength-of-preference'
author: "C E R Edmunds"
date: "20-02-2019"
output:
  html_document:
    df_print: paged
---



```{r Setup, message=F, echo=F, results='hide'}
rm(list=ls()) 

require(data.table); require(plyr); require(lme4); require(ggplot2); require(MuMIn);
require(GGally)

require(RePsychLing) # install.packages('devtools'); devtools::install_github("dmbates/RePsychLing")

fixations <- fread('NS01fixationsLong.csv', stringsAsFactors=F)

```

# Results
In total, we have `r length(unique(fixations$participantNo))` participants after excluding those for whom the fixation cross did not work (due to experimenter error) and 2 people for which the eye-tracker would not initially calibrate. 

## Exclusions
```{r Exclude participants for which I tracked wrong eye, echo=F}
effedUp <- c(1)
badCalib <- c(6, 9, 11, 14, 15, 24, 26, 34, 10, 22, 42, 47) # Wrong eye

fixations <- fixations[!participantNo %in% badCalib,]
```

As preregistered, we excluded participants on the basis of time on task. Time on task was operationalized as the proportion of time during the trial where participants were fixating on either the pictures or the response scale. We then plotted boxplots and histograms of the mean proportion for each participant to determine where a natural break point would be (and to see if any outliers were detected).

### Binary task
```{r Exclusions based on time on task: binary task, echo=F}
binary <- fixations[task=='binary' & intra_choice==1,]
binary[, onTask:= ifelse(aoi=="left" | aoi=="right" | aoi=="likertHorizontal", 1, 0)]
binary[, onTaskProp:= onTask*fixLengthTr/rt]
binary.summary <- as.data.table(aggregate(onTaskProp ~ participantNo + trial, data=binary, FUN=sum))

binary.summary.plot <- as.data.table(aggregate(onTaskProp ~ participantNo, data=binary.summary, FUN=mean))

boxplot(binary.summary.plot$onTaskProp)
title("Proportion of time spent on task in the binary task.")
# One outlier at around 0.53, propose cut off of 60% 

binary.histogram <- ggplot(binary.summary.plot, aes(x=onTaskProp)) + 
  geom_histogram(binwidth=0.01) +
  theme_minimal() +
  geom_vline(xintercept=0.6, colour="blue") +
  labs(title="Histogram of proportion of time on task for every participant in binary task", 
       x="Proportion of trial on task", y="Count") +
  xlim(c(0.5, 1))
binary.histogram

# Get excluded participant
binaryExclusions <- c(binary.summary.plot[onTaskProp<0.60, participantNo])

# Remove participant
fixations <- fixations[!participantNo %in% binaryExclusions,]
```

As can be seen from the boxplot and histogram, there was only one participant found to be an outlier (less than the first quartiler minus 1.5 times the interquartile range) in terms of time spent on task in the binary task.

### Continuous task
```{r Exclusions based on time on task: continuous task, echo=FALSE}
continuous <- fixations[task=='continuous' & intra_choice==1,]
continuous[, onTask:= ifelse(aoi=="left" | aoi=="right" | aoi=="likertHorizontal", 1, 0)]
continuous[, onTaskProp:= onTask*fixLengthTr/rt]
continuous.summary <- as.data.table(aggregate(onTaskProp ~ participantNo + trial, 
                                              data=continuous, FUN=sum))

continuous.summary.plot <- as.data.table(aggregate(onTaskProp ~ participantNo, 
                                                   data=continuous.summary, FUN=mean))

boxplot(continuous.summary.plot$onTaskProp)
title("Proportion of time spent on task in the continuous task.")
# No outliers according to boxplot 

continuous.histogram <- ggplot(continuous.summary.plot, aes(x=onTaskProp)) + 
  geom_histogram(binwidth=0.01) + 
  theme_minimal() +
  labs(title="Histogram of time on task for every participant in continuous task", 
       x="Time on task", y="Count") +
  xlim(c(0.5, 1))
continuous.histogram

# Not really needed, due to lack of exclusions. There in case change mind.
# Get excluded participant(s)
continuousExclusions <- c(continuous.summary.plot[onTaskProp<0, participantNo])

# Remove participant
fixations <- fixations[!participantNo %in% continuousExclusions,]
```

As can be seen from the boxplot and histogram, there were no participants found to be outliers in the continuous task.

Therefore, we excluded `r length(binaryExclusions) + length(continuousExclusions)` participants, resulting in `r length(unique(fixations$participantNo))` remaining participants, who completed all tasks.  


### Reaction times
Additionally, we excluded all trials with reaction times less than 200ms and trials where the reaction time is 3 standard deviations above the mean reaction time across all task trials (i.e. not including the liking rating task).

```{r Exclusions based on reaction times, echo=F}
# Excluding trials based on reaction times
fixations[, excludeTrial:= ifelse((rt<200 | rt>mean(rt)+3*sd(rt)) & task!="valuation", 1, 0)]

# Get break down of exclusions per task and per participant
rt.exclusions <- fixations[task!="valuation", list(excludeN=sum(excludeTrial)/.N), 
                      by=list(participantNo, trial, task)]
rt.exclusions.by.task <- rt.exclusions[, list(propExclude=sum(excludeN)/.N), by=task]
rt.exclusions.by.ppt <- rt.exclusions[, list(propExclude=sum(excludeN)/.N), by=.(participantNo)]

# Remove those trials
fixations <- fixations[excludeTrial==0,]
```

This resulted in excluding `r signif(rt.exclusions.by.task[task=="continuous", propExclude], 3)*100`% of trials in the continuous task, and `r signif(rt.exclusions.by.task[task=="binary", propExclude], 3)*100`% of trials in binary task. The maximum number of trials excluded for a single participant was `r max(rt.exclusions.by.ppt$propExclude)*100`% across the two tasks. 

```{r Tidying before analysis, echo=F, warning=F, message=F, results='hide'}
# Tidying
rm(binary, binary.summary, binary.summary.plot, binary.histogram, binaryExclusions, 
   continuous, continuous.summary, continuous.summary.plot, continuous.histogram, continuousExclusions, 
   rt.exclusions, rt.exclusions.by.task, rt.exclusions.by.ppt)
```

## Analysis
```{r Get data table for analysis, cache=T, echo=F}
data <- dcast(fixations, participantNo + task + taskOrder + block + trial + response + rt +
                     lValue + rValue ~ aoi,
                   fun = sum, value.var="fixLengthProp")
data[, V1:=NULL]

data[, value.difference:=rValue-lValue]
data[, attention.difference:=right-left]

data[, response:=as.double(response)]
data[task=="binary", response:= response-1]
data[task=="continuous", response:= (response-1.0)/99.0]

# Recode responses to get binary responses from continuous task
data[, recodedResponse:= response]
data[task=="continuous", recodedResponse:= ifelse(recodedResponse<=0.5, 0, 1)]

data[, `:=`(participantNo=factor(participantNo), task=factor(task))]
```

## Data exploration
```{r  Data exploration}
ggpairs(data[task=="binary", c("attention.difference", "value.difference")],
        title="Correlations between predictors for binary task.")
cor.test(data$attention.difference[data$task=="binary"], data$value.difference[data$task=="binary"])

ggpairs(data[task=="continuous", c("attention.difference", "value.difference")],
        title="Correlations between predictors for continuous task.")
cor.test(data$attention.difference[data$task=="continuous"], 
         data$value.difference[data$task=="continuous"])

ggpairs(data[task!="valuation", c("attention.difference", "value.difference")],
        title="Correlations between predictors for both tasks.")

ggplot(data[task!="valuation"], aes(x = task, y = value.difference)) +
  stat_sum(aes(size = ..n.., group = 1)) +
  scale_size_area(max_size=10)

ggplot(data[task!="valuation"], aes(x = task, y = attention.difference)) +
  geom_jitter(alpha = .1) +
  geom_violin(alpha = .75) 

ggplot(data[task!="valuation"], aes(x=attention.difference, y = rt, fill=factor(task))) +
  geom_point() +
  facet_grid(. ~ task)
ggplot(data[task!="valuation"], aes(x=value.difference, y = rt, fill=factor(task))) +
  geom_point() +
  facet_grid(. ~ task)

ggplot(data[task!="valuation"], aes(x=factor(recodedResponse), y = attention.difference, fill=factor(recodedResponse))) +
  geom_boxplot()
ggplot(data[task!="valuation"], aes(x=factor(recodedResponse), y = value.difference, fill=factor(recodedResponse))) +
  geom_boxplot()

hist(data$response[data$task=="continuous"])
hist(abs(data$response[data$task=="continuous"]-0.5))

hist(data$response[data$task=="continuous" & data$taskOrder==1])
hist(data$response[data$task=="continuous" & data$taskOrder==2])

```



So, we were interested in whether the interaction effect was greater in the continuous task or in the binary task.

One intuition was that participants might take longer to think in the continuous task than in the binary task and by taking longer to consider their choices, we might get different choices?
```{r RT: getting simplest model, cache=T, results='hide'}
rt <- lmer(rt ~ attention.difference*value.difference*task + 
             (1 + attention.difference*value.difference||participantNo), 
          data=data[task!="valuation"], REML=F, control=lmerControl(optimizer="Nelder_Mead"))
summary(rt)
summary(rePCA(rt)) # 2/4 components have variance greater than 1%

# Removing components with 0 variance: value.difference
rt1 <- lmer(rt ~ attention.difference*value.difference*task + 
             (1 + attention.difference*value.difference - value.difference||participantNo), 
          data=data[task!="valuation"], REML=F, control=lmerControl(optimizer="Nelder_Mead"))
summary(rt1)
summary(rePCA(rt1)) # 2/3 have variance>1%
anova(rt, rt1) # N.s. prefer rt1

# Remove components with smallest variance: interaction
rt2 <- lmer(rt ~ attention.difference*value.difference*task + 
             (1 + attention.difference ||participantNo), 
          data=data[task!="valuation"], REML=F, control=lmerControl(optimizer="Nelder_Mead"))
summary(rt2)
anova(rt1, rt2) # N.s. prefer rt2

rt3 <- lmer(rt ~ attention.difference*value.difference*task + 
             (1|participantNo), 
          data=data[task!="valuation"], REML=F, control=lmerControl(optimizer="Nelder_Mead"))
summary(rt3)
anova(rt2, rt3) # N.s prefer rt3

rt4 <- lm(rt ~ attention.difference*value.difference*task , 
          data=data[task!="valuation"])
summary(rt4)
anova(rt3, rt4) # Sig: prefer rt3
```

```{r Checking RT model}
models.binary <- data[task=="binary", 
               as.list(coef(lm(.SD$rt ~ .SD$attention.difference*.SD$value.difference))), 
               by=participantNo]
colnames(models.binary) <- c("participantNo", "intercept", "attention.difference", "value.difference", "interaction")

# 
# attention vs. attention (lm vs. glmer)
# 
# trial predictions, 
# 

ggplot() +
  scale_x_continuous(name="Attention", limits=c(-1, 1)) +
  scale_y_continuous(name="RT", limits=c(0, 6000)) +
  scale_linetype(name="s") +
  geom_abline(data=models.binary, 
              mapping=aes(slope=attention.difference, intercept=intercept, 
                          color=factor(participantNo)))

ggplot() +
  scale_x_continuous(name="Value", limits=c(-6, 6)) +
  scale_y_continuous(name="RT", limits=c(0, 6000)) +
  scale_linetype(name="s") +
  geom_abline(data=models.binary, 
              mapping=aes(slope=value.difference, intercept=intercept, 
                          color=factor(participantNo)))

models.continuous <- data[task=="continuous", 
               as.list(coef(lm(.SD$rt ~ .SD$attention.difference*.SD$value.difference))), 
               by=participantNo]
colnames(models.continuous) <- c("participantNo", "intercept", "attention.difference", 
                                 "value.difference", "interaction")

ggplot() +
  scale_x_continuous(name="Attention", limits=c(-1, 1)) +
  scale_y_continuous(name="RT", limits=c(0, 6000)) +
  scale_linetype(name="s") +
  geom_abline(data=models.continuous, 
              mapping=aes(slope=attention.difference, intercept=intercept, 
                          color=factor(participantNo)))

ggplot() +
  scale_x_continuous(name="Value", limits=c(-6, 6)) +
  scale_y_continuous(name="RT", limits=c(0, 6000)) +
  scale_linetype(name="s") +
  geom_abline(data=models.continuous, 
              mapping=aes(slope=value.difference, intercept=intercept, 
                          color=factor(participantNo)))
```


### Choice
Another might be that choice was affected by task.

```{r Getting simplest model, cache=T, results='hide'}
full <- glmer(recodedResponse ~ attention.difference*value.difference*task +
                (1 + attention.difference*value.difference||participantNo),
              data=data[task!="valuation",], family="binomial", 
              control=glmerControl(optimizer="Nelder_Mead"))
summary(full)
summary(rePCA(full)) # 2/4 components have variance>1%

# Removed component with smallest variance (interaction term)
choice1 <- glmer(recodedResponse ~ attention.difference*value.difference*task +
                (1 + attention.difference + value.difference||participantNo),
              data=data[task!="valuation",], family="binomial", 
              control=glmerControl(optimizer="Nelder_Mead"))
summary(choice1)
anova(full, choice1) # N.s so prefer choice1

choice2 <- glmer(recodedResponse ~ attention.difference*value.difference*task +
                (1 + attention.difference||participantNo),
              data=data[task!="valuation",], family="binomial", 
              control=glmerControl(optimizer="Nelder_Mead"))
summary(choice2)
anova(choice2, choice1) # Sig so prefer choice1

choice3 <- glmer(recodedResponse ~ attention.difference*value.difference*task +
                (1 + value.difference||participantNo),
              data=data[task!="valuation",], family="binomial", 
              control=glmerControl(optimizer="Nelder_Mead"))
summary(choice3)
anova(choice3, choice1) # Sig so prefer choice1
```

```{r Checking choice model}
models.binary <- data[task=="binary", 
               as.list(coef(glm(.SD$recodedResponse ~ .SD$attention.difference*.SD$value.difference))), 
               by=participantNo]
colnames(models.binary) <- c("participantNo", "intercept", "attention.difference", "value.difference", "interaction")

ggplot() +
  scale_x_continuous(name="Attention", limits=c(-1, 1)) +
  scale_y_continuous(name="Choice", limits=c(0, 6000)) +
  scale_linetype(name="s") +
  geom_abline(data=models.binary, 
              mapping=aes(slope=attention.difference, intercept=intercept, 
                          color=factor(participantNo)))

ggplot() +
  scale_x_continuous(name="Choice", limits=c(-6, 6)) +
  scale_y_continuous(name="RT", limits=c(0, 6000)) +
  scale_linetype(name="s") +
  geom_abline(data=models.binary, 
              mapping=aes(slope=value.difference, intercept=intercept, 
                          color=factor(participantNo)))

models.continuous <- data[task=="continuous", 
               as.list(coef(lm(.SD$rt ~ .SD$attention.difference*.SD$value.difference))), 
               by=participantNo]
colnames(models.continuous) <- c("participantNo", "intercept", "attention.difference", 
                                 "value.difference", "interaction")

ggplot() +
  scale_x_continuous(name="Attention", limits=c(-1, 1)) +
  scale_y_continuous(name="Choice", limits=c(0, 6000)) +
  scale_linetype(name="s") +
  geom_abline(data=models.continuous, 
              mapping=aes(slope=attention.difference, intercept=intercept, 
                          color=factor(participantNo)))

ggplot() +
  scale_x_continuous(name="Value", limits=c(-6, 6)) +
  scale_y_continuous(name="RT", limits=c(0, 6000)) +
  scale_linetype(name="s") +
  geom_abline(data=models.continuous, 
              mapping=aes(slope=value.difference, intercept=intercept, 
                          color=factor(participantNo)))

# Removed component with smallest variance (interaction term)
choice <- glmer(recodedResponse ~ attention.difference*value.difference +
                (1 + attention.difference + value.difference||participantNo),
              data=data[task!="valuation",], family="binomial", 
              control=glmerControl(optimizer="Nelder_Mead"))
summary(choice)

models <- data[, as.list(coef(glm(.SD$recodedResponse ~ .SD$attention.difference*.SD$value.difference))), 
               by=participantNo]
colnames(models) <- c("participantNo", "interceptF", "attention.differenceF", "value.differenceF", 
                      "interactionF")

models <- cbind(models, coef(choice)$participantNo)

ggplot(models, aes(x=attention.differenceF, y=attention.difference)) + 
  geom_point() + 
  scale_x_continuous(name="Participant wise glm", limits=c(-1, 1.5)) +
  scale_y_continuous(name="GLMEMs", limits=c(-1, 10)) +
  ggtitle("Comparison of mixed effects models with individual fits (attention)") + 
  geom_abline(intecept=0, slope=1)

ggplot(models, aes(x=value.differenceF, y=value.difference)) + 
  geom_point() + 
  scale_x_continuous(name="Participant wise glm", limits=c(-0.5, .5)) +
  scale_y_continuous(name="GLMEMs", limits=c(-.5, 1.5)) +
  ggtitle("Comparison of mixed effects models with individual fits (value)") + 
  geom_abline(intecept=0, slope=1)
```


```{r Analysis of binary task, cache=T}
binary.full <- glmer(response ~ attention.difference*value.difference +
                       (1 + attention.difference*value.difference|| participantNo),
                     family="binomial", data=data[task=="binary",])
summary(binary.full)
```

```{r Analysis of continuous task, cache=T}
continuous.full.recoded <- glmer(recodedResponse ~ attention.difference*value.difference +
                       (1 + attention.difference*value.difference|| participantNo),
                     family="binomial", data=data[task=="continuous",])
summary(continuous.full.recoded)


continuous.full <- glmer(response ~ attention.difference*value.difference +
                       (1 + attention.difference*value.difference|| participantNo),
                     family="binomial", data=data[task=="continuous",])
summary(continuous.full)

cont <- lmer(response ~ attention.difference^2 + (1+attention.difference||participantNo),
              data=data[task=="continuous"])
summary(cont)
```

So, it looks like there are main effects of attention and value on choice and main effects of task (as expected), an interaction of choice & attention and a hint of a three way interaction on rts.

# Notes
So, in this analysis there is a `r signif(cor(data[task!="valuation", value.difference], data[task!="valuation", attention.difference]),3)` correlation between attention difference and value difference: participants seem to look at the higher value option for longer.



# To do
- inverse-U relationship between value and rt? in rating tasks. find what to do with U-shaped? (perhaps $x^2$)
- need to do fitting checks and other things to avoid making silly mistakes 
- homoscedesity, leverage?

