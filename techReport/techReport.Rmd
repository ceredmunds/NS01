---
title: "NS01: Binary choice vs. evaluation"
output: html_notebook
author: "C E R Edmunds"
date: 5-11-2018
bibliography: references.bib
csl: apa.csl
---

```{r Setup, include=FALSE}

```

# Introduction

## Rationale

# Pre-registration information
For submission to aspredicted.org

## Data collection. 
No, no data have been collected for this study yet. 

## Hypothesis. What's the main question being asked or hypothesis being tested in this study?
We are interested in the effects of attention (as measured by time spent looking at an object using eye-tracking) and value (as elicited from the subjects directly via ratings) when determining choices between two objects (such as between two bags of chips, or two pictures of nature, or between two fruits). In previous experiments, we have found that choice is predicted by an interaction of attention and value: people attend to objects they like more and are more likely to choose them. However, in other experiments there are only additively separable effects of attention and value on choice: people are more likely to pick the option they value more and/or they are more likely to choose the option they attend to more, but that these effects do not interact (i.e. looking more does not have a bigger effect when the value difference is bigger). 
 
The current experiment will attempt to identify which properties lead to the interactive vs. additive effect of attention and value. Here, we will compare simple binary choice between two pictures (Would you prefer Picture A or Picture B on your wall?) with a strength of preference comparison (By how much would you prefer Picture A over Picture B, or vice versa?). We hypothesise that the size of the interaction term will be greater in the strength-of-preference condition than in the choice condition. 

## Dependent variable. Describe the key dependent variable(s) specifying how they will be measured.
The dependent variables will be the choice that each participant makes on each trial, the proportion of time spent looking at each option on each trial and the number of fixations of each option on each trial. 

## Conditions. How many and which conditions will participants be assigned to?
Each participant will complete both a binary choice tasks and a binary evaluation task in a counterbalanced order. 

## Analyses. Specify exactly which analyses you will conduct to examine the main question/hypothesis.

## Outliers and Exclusions. Describe exactly how outliers will be defined and handled, and your precise rule(s) for excluding observations.

We will flag participants in the following circumstances:

1. Eye-tracking calbration: Some individuals cannot be calibrated to the eye tracker, usually due to the physiology of their eye. Anyone who cannot be calibrated with our eye tracking equipment will be flagged. 

2. It is common that for a minority of subjects, despite accurate measurements during the calibration procedure, the quality of their eye tracking data during the task is poor. We will exclude these by measuring the proportion of each trial where there is a valid gaze location recording, and the proportion of each trial where attention was measured as being within an Area Of Interest. Subjects who fall outside 3 standard deviations away from the mean on either of these measures will be flagged. 

3. Participants who have autocorrelation in their choices that falls outside 3 standard deviations from the mean will be flagged. 

4. Participants whose mean entropy falls outside 3 standard deviations from the mean will be flagged. 

If there are significant differences between the first and second tasks (i.e. order effects), the second block will be excluded from further analyses. <!--How exactly are we checking that exactly?-->

Trials for which the reaction time was shorter than 200ms and above the participant's mean reaction time plus 3 S.D. will be excluded. 

## Sample Size. How many observations will be collected or what will determine sample size?
We will run testing until either a) we collect the data of 50 participants after exclusions, or b) we attempt data collection from 80 participants; whichever comes first. 

## Other. Anything else you would like to pre-register? 
We will collect age, and gender for all participants. We will not report the summary statistics of these variables, nor include them as covariates in our regression analyses, unless requested by referees during the publication process.

## Title.
Strength-of-preference vs. decisions in binary choice

# Method

```{r Preprocessing, include=FALSE}

```

## Participants
```{r Descriptive statistics, include=FALSE}

```

All participants were recruited from the University of Warwick’s volunteer subject pool and paid £5 for their participation.

## Design

## Materials
Eye tracking was performed using an EyeLink 1000 with desk mounted chin rest. Monocular eye movements were recorded at 500Hz and fixations were identified by the eye tracker using velocity algorithms. The Areas of Interest were defined as a rectangle around the images positions on the screen. The rectangle was larger than the image by 50 pixels on all sides. 

## Stimuli and choices
The stimuli were chosen from the International Affective Picture System [@Lang:2008]. The pictures were all mildly positive in affect (average, male and female ratings between 5=neutral and 7=mildly positive) and had differences in value ratings of no more than 1.5 between men and women. Furthermore, after visual inspection, 7 images were removed for containing pornographic images and 32 images were removed because the had a portrait aspect ratio. The 200 stimuli for each participant were randomly sampled without replacement from the 253 pictures that met these criteria. The participant's choices were generated by pairing the first stimulus with the hundred-and-first, the second with the hundred-and-second and so forth. 

## Procedure

The experiment was displayed on a black background with white text and response scales. After being introduced to the experiment and providing information about their age and gender, participants judged how much they liked each picture on a vertical Likert scale (1=strongly dislike, 7=strongly like). Each of the 200 stimuli were displayed once in a random order. Participants were offered the chance to take a self-paced break every 50 stimuli. A blank, black screen was displayed for 500ms between each rating. 

Following the rating task, the eye-tracker was calibrated. <!-- Details?--> In following two tasks, the eye-tracker was recalibrated every 13 trials (i.e., before each task and between trials 12-13, 25-26, and 38-39). At the beginning of each choice trial, a fixation cross was displayed until the participant had stared at it for at least 300ms. In both tasks, after the fixation cross two landscape stimuli (each 514 x 384px) were displayed side by side. The response scale was presented horizontally centered, below the stimuli. For the binary choice task, two labels ("Option A" and "Option B") were shown underneath the appropriate stimuli. The current choice was signified by a red, square marker (30 x 30px) above the label. For the strength of preference task, the response scale was a white bar displayed underneath the stimuli that extended from the middle of one stimulus to the middle of the other. A red marker slid along the bar to signify the amount of preference for each option. The end of the scales were marked "Option A" and "Option B." In this task participants could move the square to any point along the line using the mouse. To respond in both tasks, the participants had to press the left mouse button. Reaction times were measured from the start of the trial to the beginning of the mouse click (i.e. the program did not wait for the release of the mouse button). A blank, black screen was displayed for 500ms between each trial.

## Analysis
The continuous scale was split into a hundred bins. 

# Results
## Exclusion criteria
```{r Data cleaning, include=FALSE}

```

## Analysis
[NS: Can we add a R-code like model specification:

For within-subjects analysis:
glmer(choice ~ value.difference * attention.difference * condition + (1 | value.difference * attention.difference * condition || subject), family=binomial)

For first block only between-subjects analysis

glmer(choice ~ value.difference * attention.difference * condition + (1 | value.difference * attention.difference || subject), family=binomial)




```{r Analysis}

```

# References
